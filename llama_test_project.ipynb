{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielhcg/AntiSmishGPT/blob/main/llama_test_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llamaapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqrsfX8Dx9cq",
        "outputId": "ba1a0a8e-44d4-4b89-8212-ae4a6779ccde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llamaapi in /usr/local/lib/python3.10/dist-packages (0.1.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.5 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (3.9.5)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (1.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from llamaapi) (2.31.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->llamaapi) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->llamaapi) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MKUtmpXJxvfo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from llamaapi import LlamaAPI\n",
        "from google.colab import userdata\n",
        "from tqdm import tqdm\n",
        "import re  # Ensure 're' module is imported\n",
        "import time\n",
        "from google.colab import drive  # Import the drive module from google.colab\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the SDK\n",
        "llama = LlamaAPI(userdata.get('LLAMA-API-KEY'))"
      ],
      "metadata": {
        "id": "HdWUlTqBAugg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TRLzCxFd7nYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_sms_legitimacy(message, model):\n",
        "    request_message = f\"Is this message real or fake. Do not give an explanation: {message}\"\n",
        "    while True:\n",
        "        try:\n",
        "            response = llama.run({\n",
        "                \"model\": model,\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": request_message}]\n",
        "            })\n",
        "\n",
        "            try:\n",
        "                response_json = response.json()\n",
        "                used_model = response_json.get('model', 'Unknown model')\n",
        "                content = response_json['choices'][0]['message']['content']\n",
        "                return content, used_model\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(\"Error decoding JSON:\", e)\n",
        "                print(\"Raw response text:\", response.text)\n",
        "                time.sleep(1)  # Wait for a second before retrying\n",
        "        except Exception as e:\n",
        "            print(\"Error during API request:\", e)\n",
        "            time.sleep(1)  # Wait for a second before retrying\n",
        "\n",
        "# Specify the model you want to use\n",
        "model_to_use = \"gemma-7b\"\n",
        "\n",
        "# Read messages from an Excel file\n",
        "#input_file = os.path.abspath('/content/drive/MyDrive/Daniel hernandez/Projects/AntiSmishGPT/datasets/staged_sets/divided_mendeley_set/mendeley_set_1.xlsx')\n",
        "input_file = '/content/drive/MyDrive/Daniel hernandez/Projects/AntiSmishGPT/datasets/staged_sets/divided_mendeley_set/mendeley_set_1.xlsx'\n",
        "df = pd.read_excel(input_file, header=None)\n",
        "df.columns = ['message']\n",
        "\n",
        "# Process each message and get legitimacy determination\n",
        "determinations = []\n",
        "models = []\n",
        "for i, message in enumerate(df['message'], start=1):\n",
        "    determination, model = check_sms_legitimacy(message, model_to_use)\n",
        "    determinations.append(determination)\n",
        "    models.append(model)\n",
        "    print(f\"Message {i}: {determination} (Model: {model})\")\n",
        "\n",
        "# Add the determinations to the DataFrame\n",
        "df['determination'] = determinations\n",
        "df['model'] = models\n",
        "\n",
        "# Get the directory of the input file\n",
        "input_dir = os.path.dirname(input_file)\n",
        "\n",
        "# Create the output file path\n",
        "output_file = os.path.join(input_dir, 'processed_mendeley_set_1.xlsx')\n",
        "\n",
        "# Save the results to a new Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(\"Legitimacy check completed. Results saved to:\", output_file)"
      ],
      "metadata": {
        "id": "VnnDFlo4hAo9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}